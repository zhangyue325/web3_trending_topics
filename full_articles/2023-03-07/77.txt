 

 

训练和运行 AI 模型是计算密集型且成本高昂的工作，且数据贡献者不能从中得到公平的酬劳，去中心化技术能否提供解决方案？

 

去中心化技术能为 AI 模型做什么
-----------------

 

许多人认为所有的数字服务与现实世界中的同类服务相比，在能源消耗方面基本上是「免费」的，但事实并非如此。一些人常把矛头指向加密货币网络（尤其是那些依赖于工作量证明共识机制的网络），因为它们使用了电力，但批评者经常忽略一个事实，即每种数字服务的过程都需要计算能力，无论是你在 Netflix 上观看电视节目，还是你在超市刷卡付款。真正的问题不一定是这些服务消耗了多少电力，而是消费者从服务中获得的效用是否值得为此付出代价。

 

云计算的出现使企业家不再需要建立高能耗的数据中心，但这只意味着成本被转移到向微软 Azure、亚马逊网络服务或谷歌云平台等支付服务费用上。 鉴于对 ChatGPT 的巨大需求，OpenAI 首席执行官 Sam Altman 没有透露运行 ChatGPT 的确切成本，只是在一条推文中称其为「令人瞠目结舌」。然而，据独立估计，其成本约为每天 10 万美元，换句话说，每月高达 300 万美元以上。

 

同样值得注意的是，预估的运行 ChatGPT 的每日成本并不包括前期训练模型所消耗的能量——这是一个摄取大量数据的过程，是一个能源密集型的过程，也不包括对后续数据集的进一步训练成本。因此，Sam Altman 强调迫切需要尽快开始对 OpenAI 的创造进行货币化就不足为奇了。我们在 AI 生成的图像服务中看到了类似的轨迹，比如 OpenAI 的[DALL-E](https://openai.com/dall-e-2/)，它从社交媒体上获得了初期关注，然后引入了基于信用的服务，还有[Midjourney](https://midjourney.com/)，它允许在收费前得到 25 张免费的图像。

 

到目前为止，我们认为所有费用都是由负责软件开发的公司透明地承担着，但也有一些人发出了不同的声音，他们认为帮助创建这些模型的训练数据的不知情贡献者应该为他们的奉献得到酬劳。

 

编写代码用于训练 GitHub 的 CoPilot 的开发者，创作图像输入 Midjourney 或 DALL-E 的艺术家，以及其小说或 Reddit 投稿被用作 ChatGPT 原材料的作家，都对他们的版权作品被用于商业目的而没有支付任何酬劳这一事实表示不快。目前正在采取法律行动，这是一个[里程碑式的案件](https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart)。

 

有争议的不仅仅是使用受版权保护的材料，还有与训练数据中不正确的事实有关的潜在风险因素。虽然 ChatGPT 可以非常流畅地进行交流，但它有时也会作出与事实不符的声明，原因很简单，因为它是用没有经过准确性筛选的数据进行训练的。对于任何以用户生成内容为输入的软件来说，这都是一种风险。亚马逊的 Echo 设备因为向一个孩子提出[致命的挑战而受到批评](https://www.theverge.com/2021/12/28/22856832/amazon-alexa-challenge-child-dangerous-electricity-algorithm)，这可能导致他们触电身亡。

 

获得正确的激励
-------

 

上述例子表明，大型语言模型（LLM）消耗了大量的计算能力和数据，而目前这些都没有得到正确的激励。随着时间的推移， AI 的使用将不再是一种炒作驱动的新奇事物，而是成为商业模式的一部分，人们期望计算资源和可验证数据的定价能够接近每个商业案例的最佳水平。

 

问题是这种资源分配将如何决定。Konstantinos Sgantzos 和 Ian Grigg 的一篇[论文](https://www.mdpi.com/1999-5903/11/8/170)指出，「今天数据科学的最大挑战之一是收集适当的数据集，可以用来训练神经网络」，并得出结论「因此，区块链不仅是深度学习数据的理想存储，它们包括许多值得分析的数据，而且它们是训练的框架本身的理想存储。随着时间的推移，我们预计基于假名和激励模型，区分好数据和坏数据会变得更加容易」。

 

在他们的论文中，他们还强调了基于区块链的自动支付的潜力，可以为数据和查询执行提供一种廉价且有效的按使用付费机制。 

 

同样，[Ocean Protocol 的 Trent McConaghy 强调了区块链技术](https://medium.com/@trentmc0/ai-daos-series2-3876510d6eb4)在 AI 中的潜力，可以提供以下好处：

 

* 带来更多的数据，从而产生更好的模型；
* 带来高质量的新数据，并因此带来高质量的新模型；
* 允许共享 AI 训练数据和模型的控制权；
 

这是大家渴望创建的一个让数据提供者和内容创造者可以公平地因其努力而得到应有的酬劳的世界，以及企业家和技术专家能够吸引投资以继续推动创新的界限，而并不仅仅是一个利他主义问题。

 

AI 发展的方向对人类的未来至关重要。我们需要认真讨论改善开发、培训和运行这些 LLM 和建立在它们之上的应用程序的激励模式。一些人已经公开质疑由大型科技公司控制 LLMs 和用于训练它们的数据集是否[合适](https://www.project-syndicate.org/commentary/preventing-tech-giants-from-monopolizing-artificial-intelligence-chatbots-by-diane-coyle-2023-02?utm_source=twitter&utm_medium=organic-social&utm_campaign=page-posts-jan23&utm_post-type=link&utm_format=16:9&utm_creative=link-image&utm_post-date=2023-02-02)。已经有人提议由政府资助的项目，在这个领域与大科技公司竞争。在这种情况下，人们可能会质疑由国家利益提供或认可的数据集是否比大公司使用的数据集更中立，又或者这只是另一种扭曲了激励机制的方法。

 

像 OpenAI 这样的组织已经在公开思考这些问题，并在 2 月 16 日发表了一篇[博文](https://openai.com/blog/how-should-ai-systems-behave/)，解释了他们改善软件行为的计划，并概述了让更多公众参与软件运作的策略。

 

关于 AI 的危险已经写了很多，它有可能会有自己的想法和智慧，创造一个消灭人类的天网式场景。真正的危险可能更多的是，在不合格的数据上训练出来的激励不足的模型最终可能会阻碍有益 AI 的广泛采用，从而将这种技术创新的真正好处推迟几年，甚至几十年才发挥作用。正如 Sgantzos 和 Grigg 在他们论文中建议的那样，「区块链的不变性构建了一个富有成效的环境，可以为深度学习创造高质量、永久性和不断增长的数据集。」因此，区块链技术与 AI 的融合可能非常值得探索，以便为 LLM 的发展创造一个适当激励的环境。

