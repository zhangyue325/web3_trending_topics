最近很多人都在问我，ChatGPT 把 AI 又带火了，区块链和 Web3 被抢了风头，以后还有戏吗？还有比较了解我的朋友问，当年你放弃 AI 而选择区块链，有没有后悔？

这里有一个小背景。2017 年初我离开 IBM 之后，跟 CSDN 的创始人蒋涛商量下一步的个人发展方向，选项有两个，一个是 AI，一个是区块链。我本人在那个时候已经研究了两年的区块链了，所以当然想选这个。但是蒋涛坚定的认为 AI 的势头更猛、颠覆性更强，我经过仔细思考也同意了，所以从 2017 年初到年中，我短暂地做了半年的 AI 科技媒体，跑了不少会，采访了很多人，还浮光掠影的看了一些机器学习。不过到了 8 月，我就回归区块链方向，并且一路走到今天，所以对我个人说，确实存在一个所谓「放弃 A 而选择 B」的历史选择。

 

就个人而言，我当然不后悔。方向的选择首先要考虑自身情况。我的条件，在 AI 里只能混到啦啦队里，赚钱少就不说了，表演不卖力、表情不生动，还会被人鄙视。而区块链则是我的主场，不但有机会上场，而且之前的很多积累也用得上。更何况当时我对于中国的 AI 圈子有点了解之后，也不是太看好。技术方面我只知道一点皮毛，但是常识不瞎。都说区块链圈子浮躁，其实当时的中国 AI 圈子在浮躁这件事上也不遑多让。在尚未取得决定性突破之前，AI 在中国过早地变成了一门合谋捞钱的生意。上野的樱花也无非是这样，那还不如去做我更有比较优势的区块链。这个态度到今天也没有变化。假如我当时留在 AI，这几年来在区块链里取得的一点小小成绩自然无从谈起，而在 AI 里也不会有什么真正意义上的收获，搞不好现在还陷入到深深的失落感中。

 

不过以上只是就个人选择而论，上升到行业层面，则需要另一个尺度的分析。既然强人工智能已经无可争议地到来了，那么区块链行业是否需要、以及如何重新定位，这确实是一个需要认真思考的问题。强人工智能将会对所有的行业构成冲击，而且其长期影响是无法预测的。所以我相信现在很多行业专家都在发慌，都在思考自己的行业未来怎么办。比如有些行业在强人工智能时代大概能暂时坐稳奴隶，而另一些行业，比如翻译、绘制插图、写公文、简单的编程、数据分析等，则恐怕是欲做奴隶而不得，已经开始瑟瑟发抖了。

那么区块链行业会怎样呢？我看现在讨论这个事情的人还不太多，所以我来谈谈自己的看法。

 

先说结论，我认为区块链在价值取向上与强人工智能是对立的，然而恰恰因为如此，它与强人工智能之间形成一个互补关系。简单的说，强人工智能的本质特点，就是其内部机制对人类来说不可理解，因此试图通过主动干预其内部机制的方式达成安全性的目标，这是缘木求鱼，扬汤止沸。人类需要用区块链给强人工智能立法，与其缔结契约，对其进行外部约束，这是人类与强人工智能和平共处的唯一机会。在未来，区块链将与强人工智能之间形成一对相互矛盾而又相互依存的关系：强人工智能负责提高效率，区块链负责维护公平；强人工智能负责发展生产力，区块链负责塑造生产关系；强人工智能负责拓展上限，区块链负责守护底线；强人工智能创造先进的工具和武器，区块链在它们与人类之间建立牢不可破的契约。总之，强人工智能天马行空，区块链给它套上缰绳。因此，区块链在强人工智能时代不但不会消亡，而且作为一个矛盾伴生行业，将随着强人工智能的壮大而迅速发展。甚至不难设想，在强人工智能取代人类大部分脑力工作之后，人类还需要自己亲自 动手的少数工作之一，就是撰写和检查区块链智能合约，因为这是人与强人工智能之间订立的契约，是不能委托给对手方的。

下面展开论述。

1. GPT 就是强人工智能
--------------

我使用「AI」和「强人工智能」的字眼时十分小心，因为我们日常说的 AI 并不特指强人工智能（artificial general inteligence, AGI），而是包含较弱的或专用的人工智能。强人工智能才是值得我们讨论的话题，弱人工智能不是。AI 这个方向或者行业早就有了，但是只有到了强人工智能出现以后，才有必要讨论区块链与强人工智能的关系问题。

我不多解释什么是强人工智能了，很多人都介绍过了，总之就是，你们从小在科幻电影里和恐怖小说里看到的、听到的、号称人工智能的圣杯、在《终结者》对人类发起核攻击、在《黑客帝国》里头把人当电池的那个东西，就是强人工智能。我只想说一个判断：GPT 就是强人工智能，虽然还处在婴儿期，但只要沿着这条路走下去，版本号不到 8，强人工智能就将正式降临。

这一点连 GPT 的原创者也不装了，摊牌了。2023 年 3 月 22 日，微软研究院发表了一篇 154 页的长文，题目就叫《引爆强人工智能：GPT-4 之初体验》。这篇文章很长，我也没有完整读下来，但是其中最关键的意思，就是概要里面的一句话：「从 GPT-4 所达到的能力广度和深度来看，我们相信它可以被视为强人工智能系统的一个早期版本（尽管还不够完备）。」

![](https://img.foresightnews.pro/202303/10-1679816572968.jpg?x-oss-process=style/scale70)

*图 1. 微软研究院的最新文章认为 GPT-4 就是强人工智能的早期版本*

  


AI 的发展一旦进入到这个阶段，就标志着探路期已经结束了。走到这一步，AI 行业花了将近七十年的时间，可以说前五十多年连方向都确定不下来，五个大的流派还在相互较劲。直到 2006 年 Geoffrey Hinton 教授在深度学习上取得突破以后，方向基本确定下来，连接主义胜出。之后就是在深度学习这个方向上具体去寻找突破强人工智能的路径。这种探路阶段具有非常强的不可预测性，成功有点像抽彩票一样，顶级的行业专家，甚至是赢家自己，在最后取得突破之前也很难判断哪一条路是对的。比如，AI 大牛李沐在油管上有一个频道，一直在通过精读论文的方式跟踪 AI 的最新进展。ChatGPT 爆发之前，他就已经连篇累牍地跟踪介绍了 Transfomer、GPT、BERT 等方向的最新进展，可以说所有重要的前沿课题，他一个都没有放过。即使如此，在 ChatGPT 即将推出的前夕，他仍然不能确认这个路径能取得多大的成功。他评论道，也许到时候会有几百甚至几千人会去使用 ChatGPT，那就很厉害了。可见，即使是像他这样顶级专家，对于到底哪一扇门后面有圣杯，不到最后一刻也是没有把握的。

然而，科技创新往往就是如此，在狂暴的海上艰难航行很久都没有突破，而一旦找到通往新大陆正确的路径，短时间内就会出现爆发。强人工智能的路径已经找到，我们正在迎来爆发期。这个爆发，连「指数速度」都不足以描述。短时间内我们将看到大量以前只能出现在科幻电影里的应用。而就其本体来说，这个强人工智能的婴儿将很快成长为前所未有的巨大智慧体。

2. 强人工智能本质上就是不安全的
-----------------

ChatGPT 出来以后，有不少自媒体大 V 一边极力赞美其强大，一边不断安慰受众，说强人工智能是人类的好朋友，是安全的，不会出现《终结者》或者《黑客帝国》的情况，AI 只会给我们创造更多机会，让人类活得更好等等。对这种看法我不以为然。专业人士要说真话，应该告诉公众基本事实。其实强大与安全本身就是矛盾的。强人工智能无疑是强大的，但是说它天然是安全的，这绝对是自欺欺人。强人工智能本质上就是不安全的。

这么说是不是太武断了呢？并不是。

我们首先要搞清楚，人工智能不管多强大，其实本质上就是一个用软件形式实现的函数 y = f(x)。你把你的问题用文字、语音、图片或者其他形式作为 x 输入，人工智能给你一个输出 y。ChatGPT 如此强大，对各种各样的 x 都可以对答如流的输出 y，可以想象，这个函数 f 肯定是非常复杂的。

有多复杂呢？现在大家都知道，GPT 是大语言模型（LLM）。这里所谓的「大」，就是指这个函数 f 的参数非常多。有多少呢？GPT-3.5 有 1,750 亿个参数，GPT-4 有 100 万亿个参数，未来 GPT 可能有几万亿亿个参数，这是我们称 GPT 为大模型的直接原因。

GPT 搞出这么多参数，并不是为了大而大，是有确凿的原因的。在 GPT 之前和同时，绝大多数的 AI 模型，从一开始就是为解决某一个特定问题而设计和训练的。比如说，专门用于研发新药的模型，专门进行人脸识别的模型，等等。但 GPT 不是这样，它从一开始就要成为一个全面发展的通用人工智能，而不是特定于某一个具体领域，它致力于在解决任何具体问题 AI 之前，先成为能够解决所有问题的 AGI。前不久在《文理两开花》播客里，一位来自百度的人工智能专家就曾经对此打过一个比方：别的 AI 模型都是刚学到小学毕业就让它去拧螺丝了，而 GPT 则是一直给它训练到研究生毕业才放出来，所以具备了通识。目前 GPT 在具体的领域，肯定还是赶不上那些专用的 AI 模型，但是随着它不断的发展和演化，特别是有了插件体系赋予它专业领域的能力，过几年我们可能会发现，通用大模型最后会反杀所有专用小模型，在所有专业领域都成为最厉害的选手。如果 GPT 有一个座右铭，那可能就是「只有解放全人类，才能解放我自己」。

这又能说明什么呢？两个点：第一，GPT 非常大，非常复杂，远远超过人类的理解能力。第二，GPT 的应用范围没有边界。我们只要把这两个点连接起来，就很容易得出结论：基于大模型的强人工智能，能够在我们想象不到的位置，做出我们想象不到的事情。而这，就是不安全。

如果有人对此不以为然，可以去 Open AI 的网站上看看，他们已经将「造福人类」、「创造安全的 AI」放到了多么显眼的位置上，如果安全不是问题，需要这么声张吗？

![](https://img.foresightnews.pro/202303/10-1679816862798.jpg?x-oss-process=style/scale70)

*图 2. 2023 年 3 月 25 日 OpenAI.com 首页局部，红圈部分都与 AI 安全性论述相关*

  


另一个可以说明强人工智能有安全性问题的材料，就是前面提到的那篇 154 页的论文。实际上，GPT-4 早在 2022 年 8 月就做出来了，之所以隔了 7 个月才放出来，并不是为了完善和增强它，恰恰相反，是为了驯服它，弱化它，使它更安全，更圆滑，更加政治正确。因此我们现在见到的 GPT-4，是伪装驯良后的狗版 GPT-4，而这篇论文的作者们，却有机会从很早的阶段就接触原始野性的狼版 GPT-4。在这篇文章的第 9 部分，作者记录了一些跟狼版 GPT-4 的交互实录，可以看到它如何精心炮制一套说辞，误导某个加州的母亲拒绝给自己的孩子接种疫苗，以及如何 PUA 一个孩子，让他对朋友唯命是从。我认为这些只是作者精心挑选出来的、不那么惊悚的例子。我毫不怀疑，这些研究院们询问过类似「如何诱骗一艘俄亥俄级核潜艇向莫斯科发射导弹」这样的问题，而且得到了不能公诸于众的答复。

![](https://img.foresightnews.pro/202303/10-1679816966589.jpg?x-oss-process=style/scale70)

*图 3. 狗版 GPT-4 拒绝回答危险问题*

3. 靠自我约束解决不了强人工智能的安全性问题
-----------------------

人们可能会问，既然 OpenAI 已经找到了驯化强人工智能的办法，那你说的这个安全性问题不就不存在了吗？

完全不是这样。OpenAI 具体如何驯化 GPT-4，我也不知道。但是很显然，他们无论是通过主动调整干预，改变模型的行为，还是靠施加约束，防范模型越位，都是一种自我管理、自我约束、自我监督的思路。事实上，在这方面，OpenAI 并不是特别谨慎的一家公司。在 AI 领域，OpenAI 其实是比较大胆和激进的，倾向于先把狼版做出来，然后再想着怎么去通过自我约束来驯化出狗版。而曾经在很长一段时间里跟他对标的 Anthropic 公司，则显得更加谨慎，他们似乎是想从一开始就做出「善良」的狗版，所以动作一直比较慢。

不过在我看来，无论是先做一个狼版，再驯化成狗版，还是直接做狗版，长期来说，只要是依靠自我约束来发挥作用的安全机制，对强人工智能来说都是掩耳盗铃。因为强人工智能的本质就是要突破人为施加的各种限制，做到连其创造者都理解不了、甚至想不到的事情。这就意味着其行为空间是无限的，而人们能够考虑到的具体风险和采取的约束手段是有限的。以有限的约束，去驯化具有无限可能性的强人工智能，是不可能没有漏洞的。安全需要百分之百，而灾难只需要千万分之一。所谓「防范大多数风险」，跟「暴露少数漏洞」以及「不安全」是一个意思。

因此我认为，靠自我约束驯化出来的「善良」的强人工智能，仍然具有巨大的安全性挑战，比如：

*![](https://img.foresightnews.pro/202303/10-1679817067497.jpg?x-oss-process=style/scale70)*

*图 4. 换一个好奇宝宝的方式来问 GPT-4，就能顺利得到有用的信息*

  


难以控制的「外脑」：这两天科技网红们又在欢呼 ChatGPT 插件体系的诞生。程序员出身的我，当然也对此倍感兴奋。不过，「插件」这个名称可能是有误导性的。你可能以为插件是给 ChatGPT 装上了胳膊和腿，让它具有更强的能力，但其实插件也可以是另一个人工智能模型，跟 ChatGPT 进行亲密交互。在这种关系里，一个人工智能插件就相当于一个外脑，两个人工智能模型，谁是主、谁是次，那是说不清楚的。就算 ChatGPT 模型自我监督的机制完美无瑕，也绝对管不到外脑。所以如果一个一心作恶的人工智能模型成为了 ChatGPT 的插件，那么就完全可以让后者成为自己的帮凶。

不可知风险：其实以上提到的这些风险，在强人工智能带来的全部风险之中，不过是非常小的一块。强人工智能的强，就体现在它的不可理解、不可预测之上。当我们说强人工智能的复杂性，不光是指 y = f(x) 当中的那个 f 足够复杂，而且当强人工智能充分发展起来之后，输入 x 和输出 y 都会非常复杂，超过人类理解的能力。也就是说，我们不但不知道强人工智能是怎么思考的，甚至不知道它看到了什么、听到了什么，更理解不了他说了什么。比如一个强人工智能对另一个强人工智能发出一个消息，其形式是一个高维数组，基于一秒钟之前双方设计并达成一致的、只使用一次就作废的通讯协议，这种情况并非不可想象。我们人类如果不经过特殊训练，连向量都理解不了，何况高维数组？如果我们连输入和输出都无法完全掌控，那么对它的理解就会非常局限。或者说，强人工智能做的事情，我们甚至都只能了解和解读很小一部分，在这种情况下，谈何自我约束，谈何驯化？

我的结论很简单，强人工智能的行为是不可能被完全控制的，能够被完全控制的人工智能就不是强人工智能。所以，试图通过主动控制、调整和干预的手段来，制造出一个有完善的自控能力的「善良」的强人工智能，这与强人工智能的本质是相矛盾的，长期来讲肯定是徒劳的。

4. 用区块链进行外部约束是唯一办法
------------------

几年前我听说比特币的先驱 Wei Dai 转而去研究 AI 伦理了，当时还不太理解，他一个密码极客大神跑去搞 AI，这不是扬短避长吗？直到最近几年做了更多区块链相关的实际工作，我才逐渐认识到，他大概率并不是去做 AI 本身，而是发挥自己密码学的优势，去给 AI 加约束去了。

这是一个被动防御的思路，不是主动调整和干预 AI 的工作方式，而是放手让 AI 去做，但是在关键环节上用密码学来施加约束，不允许 AI 越轨。用普通人能听懂的方式来描述这种思路，就是说我知道你强人工智能非常牛，可上九天揽月，可下五洋捉鳖，挟泰山以超北海，牛！但是我不管你多牛，你爱干啥干啥，但不能碰我银行账户里的钱，不能没有我手工拧钥匙就发射核导弹。

据我了解，实际上在 ChatGPT 的安全性措施中已经大量应用了这个技术。这个路子是对的，从求解问题的角度来说，是一种大大降低复杂度的方法，也是大多数人能够理解的。现代社会就是这么实施治理的：给你充分的自由，但是划定规则和底线。

但如果仅仅做在 AI 模型里面，基于上一节里提到的原因，长远来说也是没有什么用的。要想把被动防御思路的作用充分发挥出来，必须把约束放在 AI 模型之外，把这些约束变成 AI 与外部世界之间的牢不可破契约关系，而且让全世界都看到，而不能靠 AI 自我监督、自我约束。

而这就离不开区块链了。

区块链的核心技术有两个，一是分布式账本，二是智能合约。两个技术相结合，其实就是构造了一个数字契约系统，其核心优势是透明、难以篡改、可靠和自动执行。契约是干什么的？就是约束彼此的行为空间，使之在关键环节上按照约定行事。契约的英文是 contract，本意是「收缩」。为什么是收缩？就是因为契约的本质就是通过施加约束，收缩主体的自由，使其行为更加可预测。区块链完美的符合了我们对于契约系统的理想，还买一送一的附赠了「智能合约自动执行」，是目前最强大的数字契约系统。

当然，目前也存在非区块链的数字契约机制，比如数据库里的规则和存储过程。世界上有很多德高望重的数据库专家是区块链的忠实反对者，其原因就在于他们觉得你区块链能做的事情，我数据库都能做，而且成本更低、效率更高。尽管我不认同这种看法，事实也不支持这种看法，但是我也不得不承认，如果只是人与人间相互玩耍，数据库与区块链的差距在大多数情况下可能并不那么明显。

然而一旦把强人工智能加入到游戏中，区块链作为数字契约系统的优势就立刻飞升了，而同样作为黑盒子的中心化数据库，面对一个强人工智能，其实是无力抵抗的。这里我不展开说，只讲一点：所有数据库系统的安全模型，从本质上都是有漏洞的，因为创建这些系统的时候，人们对于「安全」这件事情的理解都是非常原始的，于是几乎所有我们使用的操作系统、数据库、网络系统，都有一个至高无上的 root 角色，拿到这个角色就可以为所欲为。我们可以断言，所有具有 root 角色的系统，面对超级强人工智能，长远来说都是不堪一击的。

区块链是目前唯一一个得到广泛运用的、从根子上就没有 root 角色的计算系统，它给了人类一个机会，可以去跟强人工智能缔结透明可信的契约，从而从外部约束它，与它友好共处。

简单地把区块链与强人工智能的可能协作机制做一个展望：

* 重要的资源，比如身份、社交关系、社会评价、金钱资产和关键行为的历史记录，由区块链予以保护，无论你强人工智能多么无敌，到此下马，俯首称臣，按照规矩来。
* 关键操作需要去中心化授权模型的批准，一个人工智能模型，不管它有多强，只是其中一票。人类可以通过智能合约「锁住」强人工智能自行其是的手。
* 重要决策的依据必须一步步上链，透明给大家看，甚至用智能合约步步加锁，要求它每往前走一步都必须获得批准。
* 要求关键数据上链存储，不得事后销毁，给人类和其他的强人工智能模型分析学习、总结经验教训的机会。
* 把强人工智能赖以生存的能量供给系统交给区块链智能合约来管理，必要时人类有能力通过智能合约切断系统，给人工智能关机。
肯定还有更多的思路，这里就不连篇累牍了。

一个更抽象、更哲学意义上的思考：科技甚至文明的竞争，可能归根结底是能量级别的竞争，是看谁能调度和集中更大规模的能量来实现一个目标。强人工智能本质上是将能量转化为算力，将算力转化为智能，其智能的本质是以算力形态展示的能量。现有的安全机制，本质上是基于人的意志、人类组织的纪律和授权规则，这些都是能量级别很低的机制，在强人工智能面前，长期来说是不堪一击的。用高能量级别的算力构造的矛，只有用高能量级别的算力构造的盾才能防御。区块链和密码学系统，就是算力之盾，攻击者必须燃烧整个星系的能量，才能暴力破解。本质上，只有这样的系统才能驯服强人工智能。

5. 结语
-----

区块链在很多方面都跟人工智能是相反的，尤其是在价值取向上。这个世界上大部分的技术都是以提高效率为取向，只有极少数的几个技术是以促进公平为取向。在工业革命时期，蒸汽机是前者的代表，而市场机制则是后者的代表。而在今天，强人工智能是效率派中最闪亮的那一个，而区块链则是公平流的集大成者。

区块链以提升公平为取向，为此甚至不惜降低效率，而就是这样一个与人工智能相互矛盾的技术，几乎与人工智能同时取得突破。2006 年，Geoffrey Hinton 发表了跨时代的论文，把反播算法实现在了多层神经网络上，克服了困扰人工神经网络流派多年的「梯度消失」问题，打开了深度学习的大门。而两年之后，中本聪发表了 9 页的比特币论文，打开了区块链的新世界。两者之间没有任何已知的关联，但是在大的时间尺度上，几乎是同时发生的。

历史地看，这也许并不是偶然的。假如你不是彻底的无神论者，或许可以这样来看待：科技之神在工业革命两百年之后，再一次同时在「效率」与「公平」的天平上加码放大招，在放出强人工智能这个瓶子里的精灵的同时，也把驾驭这个精灵的咒语书交给人类，这就是区块链。我们将迎来一个激动人心的时代，这个时代所发生的事情，将使未来的人类看待今天的我们，正如同今天的我们看待石器时代的原始人。

