什么是 FVM，为什么需要它？
---------------

Protocol Labs 提到了他们去中心化互联网的三个阶段计划：

1. 建立世界上最大的去中心化存储网络。
2. 引入并保护人文数据。
3. 将检索和计算功能带到数据中，以构建可扩展的应用程序。
Filecoin 已经实现了第一步，成为拥有超过 661.54 PiB 数据存储的最大去中心化数据保管人。Filecoin 的存储市场在 2022 年第四季度继续增长，活跃交易增长了 117%，同比增长了 1,798%。

![](https://img.foresightnews.pro/202303/e59afab8c23a33ec6fb5fe3ee560f107.png?x-oss-process=style/scale70)

Filecoin 的下一步则是帮助引入并保护人文数据，这会是一个持续的过程。而要达到第三步，需要建立新的基础设施来帮助检索和计算数据，否则 Filecoin 只会成为全球各地存档数据的硬盘堆集。

这就有了 Filecoin 虚拟机 (FVM) 的诞生。**通过将虚拟机集成到 Filecoin 协议中，开发人员可以创建基于 Filecoin 存储网络的去中心化应用程序（dApps），以安全可靠的方式执行智能合约，并可以在现有的 Filecoin 数据上创建附加价值层**。

FVM 设计用于在 Filecoin 网络上执行智能合约。当部署智能合约时，它会被编译成 WASM 字节码。这使得开发人员可以创建行为符合不可变规则的有用应用程序，从而解锁各种用例，例如将 Filecoin 的所有市场引入链上、永久存储、DataDAOs 等。虽然所有这些都很好，但我们已经看到许多链在没有良好的开发者体验和缺乏开发者市场的情况下失败了。

Filecoin 决定推出并支持 FEVM。当一个 EVM 部署到 FEVM 时，它会被编译成 WASM，并在 FEVM 中创建一个 actor 实例来运行 EVM 字节码。然后，用户定义的 FEVM actor 就能够通过内置的 Market 和 Miner APIs 与 Filecoin 网络进行交互。

这对于 Filecoin 来说是非常关键的一步，因为**基于 EVM 的开发已经被证明具有良好的开发者体验，同时也有着庞大的现有开发者群体**。通过为执行智能合约提供安全可靠的环境，Filecoin VM 有助于释放 Filecoin 协议的全部潜力，为去中心化存储和计算带来新的创新应用场景。

FVM 解锁的用例
---------

虽然可以使用 FVM 构建许多不同的用例，但 Protocol Labs 和 FVM 团队提出了一份「Request for Startups」列表，他们认为这对于 Filecoin 生态的繁荣至关重要。以下是该列表中的几个重点：

* DataDAOs🌟
* ML 模型存储和增强[通过 DataDAOs]🌟🌟
* 存储入口[通过 DataDAOs]🌟🌟
* 按次付费[通过 DataDAOs]
* 游戏[通过 DataDAOs]🌟🌟🌟
* 社交[通过 DataDAOs]🌟🌟🌟
* 去中心化科学[通过 DataDAOs]🌟🌟🌟
* 跟踪和减少 Filecoin 的碳排放量🌟
* 硬件抵押借贷
* 永久存储🌟🌟
* 存储自动化（复制和修复）🌟🌟
* 无信任 FIL + 公证人🌟🌟
* KYC 和索赔证明
* 去中心化数据聚合器🌟🌟
* 访问控制
据 Protocol Labs 表示，星号表示项目在 Filecoin 网络上存在的重要性。读者也许都注意到了对 DataDAOs 的反复提及，那么它们是什么，为什么重要呢？

DataDAOs
--------

「数据是新石油」的说法近几年一直在流传。世界上最大的互联网公司一直以来都认为数据是他们最有价值的资源，无论是内部使用（市场 / 用户见解），还是外部销售数据。为什么数据有价值？数据只有在能够生成见解的情况下才有价值，而要生成见解，就需要对数据本身进行计算和解析。

在当前的 Filecoin 状态下，将数据在链上变现是不可能的，因为存储协议是点对点的，交易是在链下进行的，而结算是在链上进行的。将数据变现需要基础设施来建立访问控制系统、订阅付款系统、数据增强、包装等。

这就是 FVM 可以解锁的，采用去中心化以社区为中心的模式。DataDAO 是 DAO 的一种，其使命围绕着由利益相关者认为有价值的数据集的保护、生成、增强和推广。

DataDAO 的每个利益相关者现在都可以通过各种不同的方式进行激励，SPs 负责存储和保存，复制工作人员可以确保本地和快速的可用性，数据提供者现在可以获得对其任何数据的出售补偿，数据专家可以参与数据包装，ML 工程师可以获得提供可在加密数据上运行的模型的补偿，从而增加数据的价值。

1. 原始数据（最不具价值）
2. 打包数据
3. 数据计算
4. 可验证见解（最有价值）
在 FVM 之前的状态下，原始数据和打包数据可以上传到 Filecoin 上，但无法在链上进行访问控制。现在可以使用 FVM 进行数据计算（例如，AI / ML 模型、NFT 创建等）。尽管在 Filecoin 的当前状态下，复杂和重型计算无法在链上运行，因为 Filecoin 节点目前没有足够的计算能力。这表明有一个明确的范围用于与 Filecoin 互操作的链下 Dcompute 平台。

像 Bacalhau 这样的解决方案致力于实现基于数据的计算，并且与 Filecoin 具有紧密的互操作性。 Bacalhau 是一个相当新的项目，它可以使 Filecoin 网络变得更加有价值，因为它允许存储在 Filecoin 本身中的数据变得更有价值。

DataDAO 在其初始状态下不需要涵盖完整的数据价值链。虽然这可能是 DataDAO 的最终目标，但有许多 DataDAO 已经开始在特定的垂直领域或用例中工作。一些著名的例子包括：

* **Lagrange DAO**: 一个用于数据价值实现和去中心化科学（DeSci）的 DAO。它为 DeSci 提供了数据共享和分析空间。
* **GlacierDAO:** 一个开放包含公众利益代码的 Git 存储库的复制的 DAO。此外，它还允许用户将资金汇集在一起，以资助这些存储库在 Filecoin 网络上的复制。
* **SPN DAO:** 一种 DataDAO，使消费者能够将信用卡交易数据转化为资产，从而使他们能够直接控制其数据的使用和货币化。
* 虽然 DataDAO 目前集中于数据的收集和管理，但要提高价值链，将需要计算数据和 DCompute 基础设施。已经在这方面进行工作并专注于 Filecoin 的项目包括：
* **Bacalhau：**Bacalhau 是一个平台，通过在生成和存储数据的地方运行作业，实现快速、高效和安全的计算。通过运行任意 Docker 容器和 WebAssembly 图像作为任务，用户可以简化现有的工作流程而无需进行大量大范围重写。
* **Shale：**Shale 正在努力将云计算带入 Filecoin，使存储提供者能够利用现有的存储能力进行计算，并直接竞争其他云存储提供者，如 AWS 和 Google Cloud。公共用户将有机会从存储提供者租用计算实例，并通过本地网络访问 Filecoin+ 存储交易。这是一种类似于 Akash Network 和 StackOS 的解决方案，但它更加注重对 Filecoin 数据进行计算。
DataDAO 是一个独特的用例，只有通过 Filecoin 网络才能以去中心化的方式端到端解锁。

解决现有问题
------

Filecoin 在早期阶段仅仅是一个存储协议，而一个不断发展的协议必然存在很多需要解决的问题，比如：

1. 即使我的 SP 因未存储数据而被惩罚，我如何修复或检索我的数据？
2. 我有高质量的内容需要使用缓存层来交付我的分布式网站，而我与 SP 的所有交易都是离线进行的。
3. 如果我有企业级数据，如何在 Filecoin 上对我的数据进行门禁控制？还有很多其他问题。
Filecoin 正在努力解决这些问题，如 FVM 和 Retrieval Markets。FVM 解锁了在 Filecoin 上创建和激励数据复制的可能性，因此即使一个 SP 出现故障，数据也可以从其他节点检索或修复。

Retrieval Markets 将有助于创建分散化 CDN 网络，这对于 Web3 社交和游戏项目非常有益。或可以使用 FVM 建立具有端到端数据加密的访问控制平台，Medusa 这样的项目正在这个方向做出努力，同时还兼顾额外的与其他链的互操作层。

加强对 DCompute 基础设施的需求
--------------------

在像 Filecoin 这样的分布式数据存储系统中，对其进行计算有些困难，因为数据可能驻留在很远的许多不同节点中。聚合数据，然后对其进行计算会完全破坏去中心化存储系统的目的。

随着世界朝着在大型数据集上进行 AI 模型训练的方向发展，将大型数据集存储在 Filecoin 上具有巨大的经济价值（因为成本很低），但目前在这些系统上构建训练模型非常困难。

ChatGPT（GPT-3）是在一台具有 1000 个 V100 GPU（每个 GPU 的运算速度约为 147 TFLOPs）的计算机上训练的，平均成本约为 1000 万美元。

Stable Diffusion 是在 256 个成本接近 60 万美元的 A100 GPU 上进行训练的。

这需要巨大的计算能力，而 Filecoin 节点的当前最低要求是 8 核 GPU 和 128 GB RAM。单靠 Filecoin 无法应对我们生活在的计算密集型互联网时代。

解决这个问题的方法有两种：

1. 通过使存储规定的最低计算要求非常高，使 Filecoin 成为计算强国。这不是一夜之间就能完成的转变。这必须是一个逐渐的过程。
2. 将对 Filecoin 上的数据的计算外包给第三方 Dcompute 平台，例如 Bacalhau 和 Shale（以 Filecoin 为中心）或其他解决方案，例如 Akash Network、StackOS 等。
另一个问题是，许多训练模型已经构建完成，如果需要将数据移植到 Filecoin，计算网络还必须能够支持已经使用 TensorFlow、Ray 等构建的现有模型。

在短期内，笔者认为像 Shale、Akash 等去中心化云计算网络会在市场上胜出，因为部署容易，开发人员开销少，而在长期内，Filecoin 也必须努力成为计算强国，通过升级现有资源或寻找更有效的去中心化计算方式。

Rex St.John 在他的文章「Harvested Compute and Pervasive AI: The Protocol Labs Bull Thesis」中提出了一个更长远的解决方案，他建议 Filecoin 网络应该专注于使用 RaspberryPi 和 Nvidia Jetson 支持计算，这些单元的数量已经在市场上，可以更加一致地支持节点引导。

![](https://img.foresightnews.pro/202303/75d8bd715d13bfd325f8a75b3595d018.png?x-oss-process=style/scale70)

