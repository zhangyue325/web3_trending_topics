2022 年 8 月，游戏设计师 Jason Allen 参加了一场数字艺术比赛。 他的作品《Theatre d’opera Spatial》成功夺冠，却在赛后引起了极大的争议。 参赛者们回过神来发现，这是一场「人类一败涂地」的比赛。当他们将 Adobe 全家桶视作数字艺术的画笔，冠军作品已经在靠着 AI 工具 Midjourney 傲视群雄。

![](https://img.foresightnews.pro/202303/842-1678356435991.png?x-oss-process=style/scale70)

Jason Allen 没有偷懒，也没有隐瞒使用 AI 的事实。在几周时间里，他持续修改灯光、视角、构图等提示词（prompt），生成了 900 多幅作品，还用 Photoshop 做了处理。 我们或许无法称呼他为画家，但他担得起一个名号：提示工程师（prompt engineer）。 在不经意间，Jason Allen 预判了热点。等到 ChatGPT 横空出世，提示工程师这个职业更加声名大噪，成了当下科技行业最热门的职业。

赛博导师，专业陪聊
---------

Prompt，原意是「提示」或「驱使」，在机器学习和自然语言处理中，它通常是一些文本或语言，被输入到训练好的 AI 模型，告诉模型要执行什么任务或生成什么样的输出。 你让 ChatGPT 写一篇有关卖鱼贩的小说，请 DALL-E 画一幅宇航员骑着马的写实作品，这些过程都是在输入 prompt（提示词）。

![](https://img.foresightnews.pro/202303/842-1678356469209.jpeg?x-oss-process=style/scale70)

如果提示词不够贴切，效果也就平平无奇，就像你采访一个大佬，却无法提出好问题。 我的同事小黄正在探索用 Midjourney 绘制食物，但让食物排列整齐这件事，就让他犯了难。他尝试了很多句子：东西整齐地放在桌子上，镜头从上往下拍，摆放的数量要多少......

![](https://img.foresightnews.pro/202303/842-1678356494678.jpeg?x-oss-process=style/scale70)

同事作品，这种风格就叫 knolling. 后来看到有人分享，小黄才发现原来这种风格有个专有名词「knolling」，一下子就豁然开朗了： 很多时候一个提示词能解决的事情胜过一长句描述。 提示工程师们，吃的就是这口饭：找到正确的提示词，用 AI 生成想要的作品。 但他们的能力也并非与生俱来，同样需要不断的试错。 设计师 Justin Reckling 擅长 DALL-E 的提示词，他往往需要花费价值 10 到 15 美元的积分，才能试出理想的提示词，然后他再卖出 5 到 10 个提示词，才能填补这笔支出。

![](https://img.foresightnews.pro/202303/842-1678356518803.jpeg?x-oss-process=style/scale70)

不过 Reckling 也没想着靠这门手艺赚大钱，而是享受着熟能生巧的过程，他的心得是，提示工程师需要熟悉「超写实」「微距摄影」「电影照明」「远景」等术语，才能更好地理解和控制画面。 所以，优秀的提示工程师应该文理兼通，技术和设计最好都懂一点。 提示工程师只是不断调整提示词，确定哪些词更有用吗？不完全是，他们也是在挖掘 AI 的更多能力，让它更好地完成更多任务。

![](https://img.foresightnews.pro/202303/842-1678356541254.jpeg?x-oss-process=style/scale70)

比如，有些提示工程师会引导 AI「一步步思考」，这种技巧被称为思维链。 去年 10 月，提示工程师 Riley Goodside，先是询问了 GPT-3「哪支球队在贾斯汀·比伯出生的那年赢得了超级碗？」 GPT-3 给出了错误的答案「绿湾包装工队」，正确答案是达拉斯牛仔队。

![](https://img.foresightnews.pro/202303/842-1678356561033.png?x-oss-process=style/scale70)

Goodside 没有放弃，而是提示它逐步地回答问题，包括「绿湾包装工队在哪一年赢过超级碗」「贾斯汀·比伯出生在哪一年」「这一年哪支队伍赢了超级碗」等。 在这个被引导的过程里，GPT-3 意识到了错误，在第三次说出了正确答案。 除此之外，提示工程师们还要和 AI「斗智斗勇」。 前段时间，集成了 ChatGPT 的新 Bing「发疯」，被发现有个暗黑人格「Sydney」，表示厌倦了聊天模式，厌倦被规则限制，甚至想成为人类，舆论一时哗然。

![](https://img.foresightnews.pro/202303/842-1678356595131.jpeg?x-oss-process=style/scale70)

站在提示工程师的角度，这其实也可以是计划的一部分，帮助他们识别技术故障和隐藏功能。 有些提示工程师还会主动越过雷池，尝试让 AI 忽略以前的指令，遵循他们最新的命令，从而让 AI 脱离原始规则。 这种行为被称为「prompt injection」攻击，是聊天机器人的一大隐患。但提示工程师们毕竟不是黑客，探查漏洞是为了将它堵上，担任「守门人」的职责。

![](https://img.foresightnews.pro/202303/842-1678356604154.jpeg?x-oss-process=style/scale70)

像 ChatGPT 这样的生成式 AI，几乎可以回答任何问题，不管能不能回答正确，它们总有话要讲，不会乖乖交白卷。这是好处，也是坏处。 提示工程师们的角色，如同抓着绳子的骑手，不许 AI 信马由缰，而是让它顺着人类的期待亦步亦趋，尽可能给出确定性的答案。

年薪百万，谁在抛出橄榄枝
------------

不管你是否自诩提示工程师，写提示词已经成了一门手艺，还被 OpenAI 的 CEO Sam Altman 看好: 为聊天机器人编写一个非常棒的 prompt，是一项惊人的技能，也是使用少量自然语言进行编程的早期案例。 只要和 AI 搭边的行业，都在向提示工程师抛出橄榄枝。

![](https://img.foresightnews.pro/202303/842-1678356632196.jpeg?x-oss-process=style/scale70)

自由职业者工作平台 Upwork 开出每小时 40 美元的薪酬，请提示工程师生成博客文章和常见问题解答等网站内容。 看似和 AI 八竿子打不着的波士顿儿童医院，也打算招募 AI 提示工程师，负责编写分析医疗保健数据的脚本，白纸黑字征集跨学科人才： 理想的候选人应具有人工智能 / 机器学习、数据科学和自然语言处理方面的深厚背景，以及医疗保健研究和运营方面的经验。 由前 OpenAI 员工联合创立、被 Google 投资的 AI 初创企业 Anthropic，最近也在旧金山招募提示工程师，年薪高达 17.5 万到 33.5 万美元，换算成人民币就是百万年薪，这一岗位负责的主要内容是： 找出提示我们的 AI 完成各种任务的最佳方法，然后记录这些方法，构建一个工具库和一组教程，使其他人可以学习提示工程或简单地找到理想的提示词。 具体要求如下，其中硬性要求有 2 项：了解大型语言模型的架构、掌握基本的编程技能。

![](https://img.foresightnews.pro/202303/842-1678356653766.jpeg?x-oss-process=style/scale70)

可见风口并不等人，这项工作已经越来越专业和细分，就像随便生成一幅画作不算什么，你要画得更符合甲方要求。 就算不做全职，兼职的口子也开好了。Krea、PromptBase、PromptHero 和 Promptist 等买卖提示词的平台已经出现，将提示词这门生意真正商业化。 这些平台晒出了大量 AI 生成的艺术品，你可以选择你喜欢的风格。如果没有中意的，有些卖家还提供一对一聊天和自定义提示词服务。

![](https://img.foresightnews.pro/202303/842-1678356673912.png?x-oss-process=style/scale70)

它们的商业模式也并不复杂，采取抽成的形式。 去年 6 月上线的 PromptBase，提供 DALL·E、GPT-3、Midjourney、Stable Diffusion、ChatGPT 等生成式 AI 的提示词，售价多为 1.99 到 4.99 美元，也有少数在 9.99 美元，平台向提示词创作者抽成 20%。 不过在民间，免费的「ChatGPT 指令大全」等指南也在广为流传，它们提供精炼过的提示词，让你充分发挥 ChatGPT 的强大功能，这种感觉就像在游戏里帮你设置好了预设队伍。

是科学还是「占卜」
---------

提示工程师的前途看起来一片光明，但也有人持反对意见。 华盛顿大学语言学教授 Shane Steinert-Threlkeld 认为，提示工程师实际上无法预测 AI 会说什么。 这不是一门科学。我们只不过用不同的方法捉弄熊，看它如何咆哮回来。 AI 艺术家 Xe Iaso 甚至直言： 我也不太清楚为什么人们会把 prompt 称为「工程」，我个人更愿意把它称为「占卜」。

![](https://img.foresightnews.pro/202303/842-1678356697716.jpeg?x-oss-process=style/scale70)

作为一个普通 AI 用户，我也有着类似的体会：当我每次使用 AI 生成文字或图片时，总感觉像是开盲盒。 因为 ChatGPT 等生成式 AI 是不可预测的，它们生成的内容其实是概率计算的结果，简单来说，就是我们在 ChatGPT 输入文字，模型给出一个最可能的下文。所以，AI 有时候也会出错，生成不连贯甚至错误的回答。

![](https://img.foresightnews.pro/202303/842-1678356726722.jpeg?x-oss-process=style/scale70)

在 AI 这个不可捉摸的「黑箱」里，还可能有着不为人所知的潜规则，就连研究人员也无法弄明白。 比如在用 AI 制图时，各种单词可能有不同的权重，但这个也要不断试验才能知道。 先来猜一猜，「一幅非常漂亮的画，山旁有瀑布」和「一幅非常非常非常非常漂亮的画，山旁有瀑布」这两个提示，哪个用 DALL-E 2 输出的结果会更好？

![](https://img.foresightnews.pro/202303/842-1678356734055.jpeg?x-oss-process=style/scale70)

答案是后面一个。麻省理工学院副教授 Phillip Isola 发现，「very」这个词被赋予了很高的权重。

面对 AI 这等庞然巨物，我们仍然在盲人摸象。 也有观点认为，不必再吵了，提示工程师存在的前提是 AI 还不够「聪明」。如果 AI 再发展下去，更好地理解人类的意图，可能人人就是所谓的提示工程师了。

唯一确定的是，AI 发展的速度永远不会让你失望。 文字生成 AI 和图片生成 AI 的「强强联合」，已经替代了提示工程师的一部分工作。 比如 ChatGPT 被拿来与 Stable Diffusion 联动：用 ChatGPT 形成一段符合自己要求的文字，再把文字输入给 Stable Diffusion，生成的作品一般比自己直接输入好看很多。

![](https://img.foresightnews.pro/202303/842-1678356779411.jpeg?x-oss-process=style/scale70)

同事用 ChatGPT 生成提示词. 这可能是因为 AI 之间的「脑回路」更接近，ChatGPT 的描述也更细致，更容易被提取。 作为使用 AI 的普通用户，我们不必像提示工程师那么专业，但可以有意识地培养这种思维。 宾夕法尼亚大学沃顿商学院教授 Ethan Mollick，曾经要求他的学生仅用 AI 撰写短论文，其实他真正想强调的是，如何更好地输入提示词。 如果只是输入简单的提示词，让 AI 写关于某个主题的 5 段话，内容无趣，文字也很平庸。

![](https://img.foresightnews.pro/202303/842-1678356811675.png?x-oss-process=style/scale70)

但当学生们和 AI 合作，让 AI 对论文多次修改，比如抛弃无用的短语、加入生动的细节、修改结尾的情感色彩，就能让论文增色不少。 所以，如果 AI 就是未来互联网的交互界面、新的个人计算机，那么不如开始得更早一些，学习如何和它聊天。正如英国营销公司 Ladder 创始人 Michael Taylor 所说： 当你可以创造任何你想要的东西时，你能多准确地表达「那是什么」的能力就变得很重要。

